# TR-102-daily-diary
# daily_progress.py
"""
28-DAY DEVELOPMENT DIARY
Project: AI Product Comparison Chatbot
Technologies: Python, Tkinter, BeautifulSoup, Requests, Threading, LRU Cache
Author: < Harmanveer Singh>
"""

def main():
    daily_logs = [
        "Day 1 â€“ Project Setup:\n"
        "  â€¢ Installed necessary libraries (tkinter, requests, bs4).\n"
        "  â€¢ Created main Python file and planned GUI structure.\n",

        "Day 2 â€“ Basic GUI Design:\n"
        "  â€¢ Created Tkinter main window with title and background color.\n"
        "  â€¢ Added header and subtitle labels.\n",

        "Day 3 â€“ URL Input Section:\n"
        "  â€¢ Added two entry fields for product URLs.\n"
        "  â€¢ Added a compare button for triggering product comparison.\n",

        "Day 4 â€“ Fetching Web Data:\n"
        "  â€¢ Used requests.get() to fetch product webpage HTML.\n"
        "  â€¢ Handled basic exceptions using try-except.\n",

        "Day 5 â€“ HTML Parsing with BeautifulSoup:\n"
        "  â€¢ Integrated BeautifulSoup for parsing HTML content.\n"
        "  â€¢ Extracted product title from <title> tag for testing.\n",

        "Day 6 â€“ Title Extraction Function:\n"
        "  â€¢ Added _extract_title() method using multiple CSS selectors.\n"
        "  â€¢ Tested across Amazon and Flipkart links.\n",

        "Day 7 â€“ Price Extraction:\n"
        "  â€¢ Added regex patterns to detect â‚¹, $, â‚¬, Â£ formatted prices.\n"
        "  â€¢ Implemented graceful fallback for missing data.\n",

        "Day 8 â€“ Description Extraction:\n"
        "  â€¢ Added _extract_description() using meta and description tags.\n"
        "  â€¢ Trimmed long text and formatted clean output.\n",

        "Day 9 â€“ Feature Extraction:\n"
        "  â€¢ Parsed <li> elements for key features.\n"
        "  â€¢ Filtered short text and limited to 6â€“8 features.\n",

        "Day 10 â€“ Rating Extraction:\n"
        "  â€¢ Used regex to find patterns like '4.2 out of 5'.\n"
        "  â€¢ Added default 'N/A' for missing ratings.\n",

        "Day 11 â€“ Result Display Area:\n"
        "  â€¢ Added scrolled text area for showing comparison output.\n"
        "  â€¢ Used colored text tags for styling.\n",

        "Day 12 â€“ Comparison Report Generation:\n"
        "  â€¢ Built generate_comparison() to merge product details.\n"
        "  â€¢ Added sections for price, rating, and recommendations.\n",

        "Day 13 â€“ Smart Recommendations:\n"
        "  â€¢ Created _generate_recommendation() with helpful buying tips.\n"
        "  â€¢ Added expert advice footer in output.\n",

        "Day 14 â€“ Threading for Smooth UI:\n"
        "  â€¢ Implemented background threading to prevent GUI freeze.\n"
        "  â€¢ Compared two products asynchronously.\n",

        "Day 15 â€“ Progress Bar & Status Updates:\n"
        "  â€¢ Added animated progress bar.\n"
        "  â€¢ Updated status label dynamically for each step.\n",

        "Day 16 â€“ Added LRU Cache:\n"
        "  â€¢ Used @lru_cache to store previous extraction results.\n"
        "  â€¢ Improved performance for repeated URLs.\n",

        "Day 17 â€“ Input Validation & Error Handling:\n"
        "  â€¢ Added URL validation using urllib.parse.\n"
        "  â€¢ Used messagebox for errors and warnings.\n",

        "Day 18 â€“ Clear & Export Functions:\n"
        "  â€¢ Implemented Clear button to reset input fields.\n"
        "  â€¢ Implemented Export button to save results as .txt file.\n",

        "Day 19 â€“ UI Improvements:\n"
        "  â€¢ Adjusted fonts, colors, and padding.\n"
        "  â€¢ Added border effects and modern look.\n",

        "Day 20 â€“ Multi-site Testing:\n"
        "  â€¢ Tested on Amazon, Flipkart, and eBay.\n"
        "  â€¢ Improved selectors for better extraction coverage.\n",

        "Day 21 â€“ Code Optimization:\n"
        "  â€¢ Removed redundant lines and improved readability.\n"
        "  â€¢ Added docstrings for all functions.\n",

        "Day 22 â€“ Advanced Error Handling:\n"
        "  â€¢ Wrapped scraping with robust try-except.\n"
        "  â€¢ Handled connection errors gracefully.\n",

        "Day 23 â€“ UI Enhancements:\n"
        "  â€¢ Improved theme consistency and color contrast.\n"
        "  â€¢ Added emojis for better section clarity.\n",

        "Day 24 â€“ Testing & Debugging:\n"
        "  â€¢ Debugged threading issues.\n"
        "  â€¢ Ensured progress bar synchronization.\n",

        "Day 25 â€“ Final Touches:\n"
        "  â€¢ Improved text formatting and alignment.\n"
        "  â€¢ Optimized scroll performance.\n",

        "Day 26 â€“ Documentation:\n"
        "  â€¢ Created README.md with project overview and screenshots.\n"
        "  â€¢ Documented features and setup instructions.\n",

        "Day 27 â€“ Viva Preparation:\n"
        "  â€¢ Revised all functions and code flow.\n"
        "  â€¢ Prepared answers for common viva questions.\n",

        "Day 28 â€“ Final Submission:\n"
        "  â€¢ Uploaded final code to GitHub.\n"
        "  â€¢ Verified repository and tested final version.\n"
        "  â€¢ Project successfully completed! ðŸŽ“\n"
    ]

    print("\nðŸ“˜ 28-DAY DEVELOPMENT DIARY - AI PRODUCT COMPARISON CHATBOT\n")
    for day in daily_logs:
        print(day)
        print("-" * 80)

if __name__ == "__main__":
    main()
